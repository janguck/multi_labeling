{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from bp_mll_keras import bp_mll_loss\n",
    "import pandas as pd\n",
    "from konlpy.tag import Twitter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "\n",
    "pos_tagger = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../input/x_train.pickle', 'rb') as f:\n",
    "    x_train = pickle.load(f)\n",
    "with open('../input/x_test.pickle', 'rb') as f:\n",
    "    x_test = pickle.load(f)\n",
    "with open('../input/y_train.pickle', 'rb') as f:\n",
    "    y_train = pickle.load(f)\n",
    "with open('../input/y_test.pickle', 'rb') as f:\n",
    "    y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_dr = \"../input/stopword.txt\"\n",
    "f = open(stop_dr, 'r')\n",
    "stopword_korean = set([value.strip() for value in f.readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    return ['/'.join(t) for t in pos_tagger.pos(doc, norm=True, stem=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train  = [[i.split(\"/\")[0] for i in tokenize(j) if i.split(\"/\")[1] in ['Noun','Verb','Adjective'] and i.split(\"/\")[0] not in stopword_korean ]for j in x_train ]\n",
    "x_train = [','.join(i) for i in x_train]\n",
    "\n",
    "x_test  = [[i.split(\"/\")[0] for i in tokenize(j) if i.split(\"/\")[1] in ['Noun','Verb','Adjective'] and i.split(\"/\")[0] not in stopword_korean ]for j in x_test ]\n",
    "x_test = [','.join(i) for i in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(analyzer=lambda d: d.split(\",\")).fit(x_train)\n",
    "x_train = tfidf.fit_transform(x_train).toarray()\n",
    "x_test = tfidf.transform(x_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1343 samples, validate on 150 samples\n",
      "Epoch 1/100\n",
      "1343/1343 [==============================] - 1s 920us/step - loss: 25.8138 - acc: 0.2993 - val_loss: 21.5754 - val_acc: 0.3200\n",
      "Epoch 2/100\n",
      "1343/1343 [==============================] - 1s 535us/step - loss: 22.9015 - acc: 0.3105 - val_loss: 20.3855 - val_acc: 0.3200\n",
      "Epoch 3/100\n",
      "1343/1343 [==============================] - 1s 546us/step - loss: 20.4668 - acc: 0.3172 - val_loss: 18.3192 - val_acc: 0.3200\n",
      "Epoch 4/100\n",
      "1343/1343 [==============================] - 1s 541us/step - loss: 18.2500 - acc: 0.3142 - val_loss: 17.9331 - val_acc: 0.3200\n",
      "Epoch 5/100\n",
      "1343/1343 [==============================] - 1s 543us/step - loss: 17.1511 - acc: 0.3209 - val_loss: 17.3976 - val_acc: 0.3200\n",
      "Epoch 6/100\n",
      "1343/1343 [==============================] - 1s 536us/step - loss: 16.4961 - acc: 0.3291 - val_loss: 17.7951 - val_acc: 0.3400\n",
      "Epoch 7/100\n",
      "1343/1343 [==============================] - 1s 540us/step - loss: 16.1056 - acc: 0.3470 - val_loss: 17.7333 - val_acc: 0.3467\n",
      "Epoch 8/100\n",
      "1343/1343 [==============================] - 1s 537us/step - loss: 15.9234 - acc: 0.3656 - val_loss: 17.8057 - val_acc: 0.3733\n",
      "Epoch 9/100\n",
      "1343/1343 [==============================] - 1s 540us/step - loss: 15.7098 - acc: 0.3730 - val_loss: 17.5300 - val_acc: 0.3867\n",
      "Epoch 10/100\n",
      "1343/1343 [==============================] - 1s 544us/step - loss: 15.3518 - acc: 0.3917 - val_loss: 17.5769 - val_acc: 0.3733\n",
      "Epoch 11/100\n",
      "1343/1343 [==============================] - 1s 546us/step - loss: 15.2756 - acc: 0.4147 - val_loss: 17.6350 - val_acc: 0.3800\n",
      "Epoch 12/100\n",
      "1343/1343 [==============================] - 1s 543us/step - loss: 15.0201 - acc: 0.4334 - val_loss: 17.6728 - val_acc: 0.3867\n",
      "Epoch 13/100\n",
      "1343/1343 [==============================] - 1s 551us/step - loss: 14.8687 - acc: 0.4289 - val_loss: 17.6023 - val_acc: 0.3800\n",
      "Epoch 14/100\n",
      "1343/1343 [==============================] - 1s 553us/step - loss: 14.6502 - acc: 0.4415 - val_loss: 17.4279 - val_acc: 0.4067\n",
      "Epoch 15/100\n",
      "1343/1343 [==============================] - 1s 549us/step - loss: 14.6118 - acc: 0.4676 - val_loss: 17.3382 - val_acc: 0.4133\n",
      "Epoch 16/100\n",
      "1343/1343 [==============================] - 1s 537us/step - loss: 14.4464 - acc: 0.4743 - val_loss: 17.1473 - val_acc: 0.4333\n",
      "Epoch 17/100\n",
      "1343/1343 [==============================] - 1s 540us/step - loss: 14.3683 - acc: 0.4966 - val_loss: 17.1461 - val_acc: 0.4467\n",
      "Epoch 18/100\n",
      "1343/1343 [==============================] - 1s 536us/step - loss: 14.3600 - acc: 0.5153 - val_loss: 17.1860 - val_acc: 0.4667\n",
      "Epoch 19/100\n",
      "1343/1343 [==============================] - 1s 544us/step - loss: 14.2771 - acc: 0.5450 - val_loss: 17.3779 - val_acc: 0.4333\n",
      "Epoch 20/100\n",
      "1343/1343 [==============================] - 1s 547us/step - loss: 14.2594 - acc: 0.5488 - val_loss: 17.2868 - val_acc: 0.4333\n",
      "Epoch 21/100\n",
      "1343/1343 [==============================] - 1s 541us/step - loss: 14.1548 - acc: 0.5376 - val_loss: 17.1697 - val_acc: 0.4533\n",
      "Epoch 22/100\n",
      "1343/1343 [==============================] - 1s 533us/step - loss: 14.1389 - acc: 0.5220 - val_loss: 17.1249 - val_acc: 0.4600\n",
      "Epoch 23/100\n",
      "1343/1343 [==============================] - 1s 534us/step - loss: 14.0573 - acc: 0.5413 - val_loss: 17.2867 - val_acc: 0.4400\n",
      "Epoch 24/100\n",
      "1343/1343 [==============================] - 1s 553us/step - loss: 14.0776 - acc: 0.5748 - val_loss: 17.0482 - val_acc: 0.4867\n",
      "Epoch 25/100\n",
      "1343/1343 [==============================] - 1s 543us/step - loss: 14.0111 - acc: 0.6016 - val_loss: 17.1153 - val_acc: 0.4667\n",
      "Epoch 26/100\n",
      "1343/1343 [==============================] - 1s 550us/step - loss: 14.0062 - acc: 0.5599 - val_loss: 17.4639 - val_acc: 0.4533\n",
      "Epoch 27/100\n",
      "1343/1343 [==============================] - 1s 545us/step - loss: 13.9764 - acc: 0.5994 - val_loss: 17.3119 - val_acc: 0.4667\n",
      "Epoch 28/100\n",
      "1343/1343 [==============================] - 1s 548us/step - loss: 13.9766 - acc: 0.6150 - val_loss: 17.3437 - val_acc: 0.5000\n",
      "Epoch 29/100\n",
      "1343/1343 [==============================] - 1s 546us/step - loss: 13.9390 - acc: 0.6396 - val_loss: 17.6577 - val_acc: 0.5200\n",
      "Epoch 30/100\n",
      "1343/1343 [==============================] - 1s 540us/step - loss: 13.9316 - acc: 0.6441 - val_loss: 17.2232 - val_acc: 0.5200\n",
      "Epoch 31/100\n",
      "1343/1343 [==============================] - 1s 538us/step - loss: 13.8893 - acc: 0.6984 - val_loss: 17.1962 - val_acc: 0.6267\n",
      "Epoch 32/100\n",
      "1343/1343 [==============================] - 1s 540us/step - loss: 13.9007 - acc: 0.6791 - val_loss: 17.4720 - val_acc: 0.5333\n",
      "Epoch 33/100\n",
      "1343/1343 [==============================] - 1s 539us/step - loss: 13.8888 - acc: 0.6798 - val_loss: 17.4266 - val_acc: 0.5467\n",
      "Epoch 34/100\n",
      "1343/1343 [==============================] - 1s 544us/step - loss: 13.8730 - acc: 0.6620 - val_loss: 17.6391 - val_acc: 0.4933\n",
      "Epoch 35/100\n",
      "1343/1343 [==============================] - 1s 545us/step - loss: 13.8639 - acc: 0.6582 - val_loss: 17.6421 - val_acc: 0.5133\n",
      "Epoch 36/100\n",
      "1343/1343 [==============================] - 1s 553us/step - loss: 13.8946 - acc: 0.6858 - val_loss: 17.3784 - val_acc: 0.5267\n",
      "Epoch 37/100\n",
      "1343/1343 [==============================] - 1s 546us/step - loss: 13.8688 - acc: 0.7089 - val_loss: 17.6439 - val_acc: 0.5267\n",
      "Epoch 38/100\n",
      "1343/1343 [==============================] - 1s 541us/step - loss: 13.8467 - acc: 0.6999 - val_loss: 17.7729 - val_acc: 0.5267\n",
      "Epoch 39/100\n",
      "1343/1343 [==============================] - 1s 548us/step - loss: 13.8265 - acc: 0.6739 - val_loss: 17.7452 - val_acc: 0.5000\n",
      "Epoch 40/100\n",
      "1343/1343 [==============================] - 1s 553us/step - loss: 13.8048 - acc: 0.6597 - val_loss: 17.6029 - val_acc: 0.5267\n",
      "Epoch 41/100\n",
      "1343/1343 [==============================] - 1s 548us/step - loss: 13.8040 - acc: 0.7022 - val_loss: 17.6917 - val_acc: 0.5667\n",
      "Epoch 42/100\n",
      "1343/1343 [==============================] - 1s 545us/step - loss: 13.8179 - acc: 0.7610 - val_loss: 17.4651 - val_acc: 0.6000\n",
      "Epoch 43/100\n",
      "1343/1343 [==============================] - 1s 547us/step - loss: 13.4208 - acc: 0.8131 - val_loss: 17.2766 - val_acc: 0.6533\n",
      "Epoch 44/100\n",
      "1343/1343 [==============================] - 1s 547us/step - loss: 12.8297 - acc: 0.8541 - val_loss: 17.3465 - val_acc: 0.6267\n",
      "Epoch 45/100\n",
      "1343/1343 [==============================] - 1s 543us/step - loss: 12.6163 - acc: 0.8466 - val_loss: 17.1414 - val_acc: 0.6333\n",
      "Epoch 46/100\n",
      "1343/1343 [==============================] - 1s 545us/step - loss: 12.5580 - acc: 0.8600 - val_loss: 17.2561 - val_acc: 0.6533\n",
      "Epoch 47/100\n",
      "1343/1343 [==============================] - 1s 549us/step - loss: 12.4853 - acc: 0.8615 - val_loss: 17.1445 - val_acc: 0.6467\n",
      "Epoch 48/100\n",
      "1343/1343 [==============================] - 1s 544us/step - loss: 12.4377 - acc: 0.8608 - val_loss: 17.4411 - val_acc: 0.6467\n",
      "Epoch 49/100\n",
      "1343/1343 [==============================] - 1s 544us/step - loss: 12.3434 - acc: 0.8712 - val_loss: 17.5541 - val_acc: 0.6467\n",
      "Epoch 50/100\n",
      "1343/1343 [==============================] - 1s 544us/step - loss: 12.3240 - acc: 0.8824 - val_loss: 17.3952 - val_acc: 0.6467\n",
      "Epoch 51/100\n",
      "1343/1343 [==============================] - 1s 545us/step - loss: 12.3226 - acc: 0.8786 - val_loss: 17.0609 - val_acc: 0.6467\n",
      "Epoch 52/100\n",
      "1343/1343 [==============================] - 1s 543us/step - loss: 12.3266 - acc: 0.8891 - val_loss: 17.5305 - val_acc: 0.6400\n",
      "Epoch 53/100\n",
      "1343/1343 [==============================] - 1s 537us/step - loss: 12.2806 - acc: 0.8965 - val_loss: 17.1816 - val_acc: 0.6667\n",
      "Epoch 54/100\n",
      "1343/1343 [==============================] - 1s 543us/step - loss: 12.3208 - acc: 0.8786 - val_loss: 17.0353 - val_acc: 0.6667\n",
      "Epoch 55/100\n",
      "1343/1343 [==============================] - 1s 545us/step - loss: 12.2821 - acc: 0.9099 - val_loss: 17.5674 - val_acc: 0.6533\n",
      "Epoch 56/100\n",
      "1343/1343 [==============================] - 1s 542us/step - loss: 12.2744 - acc: 0.8958 - val_loss: 18.0098 - val_acc: 0.6467\n",
      "Epoch 57/100\n",
      "1343/1343 [==============================] - 1s 545us/step - loss: 12.2511 - acc: 0.8883 - val_loss: 17.6442 - val_acc: 0.6600\n",
      "Epoch 58/100\n",
      "1343/1343 [==============================] - 1s 540us/step - loss: 12.2833 - acc: 0.8913 - val_loss: 17.6399 - val_acc: 0.6400\n",
      "Epoch 59/100\n",
      "1343/1343 [==============================] - 1s 540us/step - loss: 12.2662 - acc: 0.8995 - val_loss: 17.7056 - val_acc: 0.6533\n",
      "Epoch 60/100\n",
      "1343/1343 [==============================] - 1s 547us/step - loss: 12.2690 - acc: 0.8972 - val_loss: 17.3513 - val_acc: 0.6600\n",
      "Epoch 61/100\n",
      "1343/1343 [==============================] - 1s 549us/step - loss: 12.2580 - acc: 0.9129 - val_loss: 18.0107 - val_acc: 0.6400\n",
      "Epoch 62/100\n",
      "1343/1343 [==============================] - 1s 540us/step - loss: 12.2584 - acc: 0.9084 - val_loss: 17.6503 - val_acc: 0.6667\n",
      "Epoch 63/100\n",
      "1343/1343 [==============================] - 1s 538us/step - loss: 12.2560 - acc: 0.8980 - val_loss: 17.9176 - val_acc: 0.6400\n",
      "Epoch 64/100\n",
      "1343/1343 [==============================] - 1s 544us/step - loss: 12.2254 - acc: 0.8868 - val_loss: 18.1198 - val_acc: 0.6133\n",
      "Epoch 65/100\n",
      "1343/1343 [==============================] - 1s 543us/step - loss: 12.2529 - acc: 0.9054 - val_loss: 17.4413 - val_acc: 0.6733\n",
      "Epoch 66/100\n",
      "1343/1343 [==============================] - 1s 541us/step - loss: 12.2511 - acc: 0.9025 - val_loss: 17.5960 - val_acc: 0.6333\n",
      "Epoch 67/100\n",
      "1343/1343 [==============================] - 1s 541us/step - loss: 12.2534 - acc: 0.8995 - val_loss: 17.3933 - val_acc: 0.6933\n",
      "Epoch 68/100\n",
      "1343/1343 [==============================] - 1s 545us/step - loss: 12.2371 - acc: 0.8965 - val_loss: 17.6373 - val_acc: 0.6533\n",
      "Epoch 69/100\n",
      "1343/1343 [==============================] - 1s 546us/step - loss: 12.2230 - acc: 0.8965 - val_loss: 17.3726 - val_acc: 0.6800\n",
      "Epoch 70/100\n",
      "1343/1343 [==============================] - 1s 545us/step - loss: 12.2155 - acc: 0.9047 - val_loss: 17.6982 - val_acc: 0.6667\n",
      "Epoch 71/100\n",
      "1343/1343 [==============================] - 1s 543us/step - loss: 12.2418 - acc: 0.8950 - val_loss: 17.5583 - val_acc: 0.6467\n",
      "Epoch 72/100\n",
      "1343/1343 [==============================] - 1s 544us/step - loss: 12.2450 - acc: 0.9211 - val_loss: 17.9792 - val_acc: 0.6600\n",
      "Epoch 73/100\n",
      "1343/1343 [==============================] - 1s 541us/step - loss: 12.2232 - acc: 0.9308 - val_loss: 17.7828 - val_acc: 0.6467\n",
      "Epoch 74/100\n",
      "1343/1343 [==============================] - 1s 545us/step - loss: 12.2424 - acc: 0.9188 - val_loss: 17.5467 - val_acc: 0.6800\n",
      "Epoch 75/100\n",
      "1343/1343 [==============================] - 1s 532us/step - loss: 12.2550 - acc: 0.9166 - val_loss: 17.6504 - val_acc: 0.6467\n",
      "Epoch 76/100\n",
      "1343/1343 [==============================] - 1s 541us/step - loss: 12.2326 - acc: 0.8913 - val_loss: 17.2720 - val_acc: 0.6933\n",
      "Epoch 77/100\n",
      "1343/1343 [==============================] - 1s 550us/step - loss: 12.2412 - acc: 0.9188 - val_loss: 17.1757 - val_acc: 0.6867\n",
      "Epoch 78/100\n",
      "1343/1343 [==============================] - 1s 546us/step - loss: 12.2359 - acc: 0.9106 - val_loss: 17.3856 - val_acc: 0.6467\n",
      "Epoch 79/100\n",
      "1343/1343 [==============================] - 1s 543us/step - loss: 12.2420 - acc: 0.8950 - val_loss: 17.9200 - val_acc: 0.6400\n",
      "Epoch 80/100\n",
      "1343/1343 [==============================] - 1s 547us/step - loss: 12.2303 - acc: 0.9069 - val_loss: 17.4584 - val_acc: 0.6600\n",
      "Epoch 81/100\n",
      "1343/1343 [==============================] - 1s 545us/step - loss: 12.2286 - acc: 0.9002 - val_loss: 17.8656 - val_acc: 0.6533\n",
      "Epoch 82/100\n",
      "1343/1343 [==============================] - 1s 545us/step - loss: 12.2287 - acc: 0.8965 - val_loss: 17.6910 - val_acc: 0.6533\n",
      "Epoch 83/100\n",
      "1343/1343 [==============================] - 1s 547us/step - loss: 12.2397 - acc: 0.9077 - val_loss: 17.7903 - val_acc: 0.6333\n",
      "Epoch 84/100\n",
      "1343/1343 [==============================] - 1s 548us/step - loss: 12.2339 - acc: 0.9025 - val_loss: 17.6401 - val_acc: 0.6533\n",
      "Epoch 85/100\n",
      "1343/1343 [==============================] - 1s 547us/step - loss: 12.2295 - acc: 0.9159 - val_loss: 17.6366 - val_acc: 0.6933\n",
      "Epoch 86/100\n",
      "1343/1343 [==============================] - 1s 544us/step - loss: 12.2227 - acc: 0.9218 - val_loss: 17.8753 - val_acc: 0.6400\n",
      "Epoch 87/100\n",
      "1343/1343 [==============================] - 1s 545us/step - loss: 12.2520 - acc: 0.9092 - val_loss: 18.1925 - val_acc: 0.6333\n",
      "Epoch 88/100\n",
      "1343/1343 [==============================] - 1s 539us/step - loss: 12.2323 - acc: 0.9218 - val_loss: 17.8647 - val_acc: 0.6533\n",
      "Epoch 89/100\n",
      "1343/1343 [==============================] - 1s 549us/step - loss: 12.2116 - acc: 0.9173 - val_loss: 17.8439 - val_acc: 0.6400\n",
      "Epoch 90/100\n",
      "1343/1343 [==============================] - 1s 544us/step - loss: 12.2175 - acc: 0.9263 - val_loss: 17.7481 - val_acc: 0.6333\n",
      "Epoch 91/100\n",
      "1343/1343 [==============================] - 1s 545us/step - loss: 12.2335 - acc: 0.9129 - val_loss: 17.7454 - val_acc: 0.6533\n",
      "Epoch 92/100\n",
      "1343/1343 [==============================] - 1s 546us/step - loss: 12.2066 - acc: 0.9151 - val_loss: 17.6769 - val_acc: 0.6667\n",
      "Epoch 93/100\n",
      "1343/1343 [==============================] - 1s 542us/step - loss: 12.2005 - acc: 0.9203 - val_loss: 17.8294 - val_acc: 0.6600\n",
      "Epoch 94/100\n",
      "1343/1343 [==============================] - 1s 537us/step - loss: 12.2048 - acc: 0.9203 - val_loss: 17.9328 - val_acc: 0.6600\n",
      "Epoch 95/100\n",
      "1343/1343 [==============================] - 1s 536us/step - loss: 12.2346 - acc: 0.9270 - val_loss: 17.7391 - val_acc: 0.6667\n",
      "Epoch 96/100\n",
      "1343/1343 [==============================] - 1s 541us/step - loss: 12.2066 - acc: 0.9255 - val_loss: 18.0050 - val_acc: 0.6467\n",
      "Epoch 97/100\n",
      "1343/1343 [==============================] - 1s 552us/step - loss: 12.1900 - acc: 0.9233 - val_loss: 18.1189 - val_acc: 0.6667\n",
      "Epoch 98/100\n",
      "1343/1343 [==============================] - 1s 551us/step - loss: 12.2095 - acc: 0.9315 - val_loss: 17.9959 - val_acc: 0.6533\n",
      "Epoch 99/100\n",
      "1343/1343 [==============================] - 1s 542us/step - loss: 12.1994 - acc: 0.9486 - val_loss: 17.8602 - val_acc: 0.6667\n",
      "Epoch 100/100\n",
      "1343/1343 [==============================] - 1s 550us/step - loss: 12.2133 - acc: 0.9278 - val_loss: 17.5666 - val_acc: 0.7000\n"
     ]
    }
   ],
   "source": [
    "n = x_train.shape[0]\n",
    "dim_no = x_train.shape[1]\n",
    "class_no = y_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_dim=dim_no, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(class_no, activation='sigmoid', kernel_initializer='glorot_uniform'))\n",
    "model.compile(loss=bp_mll_loss, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=100,validation_split=0.1)\n",
    "predict = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability:  0.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.68      0.67       161\n",
      "          1       0.47      0.33      0.39        55\n",
      "          2       0.00      0.00      0.00         1\n",
      "          3       0.71      0.71      0.71       240\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.74      0.90      0.81       566\n",
      "          7       0.64      0.47      0.54        75\n",
      "          8       0.46      0.54      0.49       170\n",
      "          9       0.60      0.57      0.58       199\n",
      "         10       0.59      0.74      0.66       455\n",
      "\n",
      "avg / total       0.64      0.71      0.67      1940\n",
      "\n",
      "Probability:  0.2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.67      0.68       161\n",
      "          1       0.50      0.29      0.37        55\n",
      "          2       0.00      0.00      0.00         1\n",
      "          3       0.72      0.70      0.71       240\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.74      0.88      0.81       566\n",
      "          7       0.65      0.45      0.54        75\n",
      "          8       0.47      0.52      0.49       170\n",
      "          9       0.60      0.54      0.57       199\n",
      "         10       0.60      0.73      0.65       455\n",
      "\n",
      "avg / total       0.64      0.70      0.67      1940\n",
      "\n",
      "Probability:  0.30000000000000004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.66      0.68       161\n",
      "          1       0.52      0.29      0.37        55\n",
      "          2       0.00      0.00      0.00         1\n",
      "          3       0.73      0.70      0.71       240\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.75      0.87      0.81       566\n",
      "          7       0.65      0.44      0.52        75\n",
      "          8       0.48      0.52      0.50       170\n",
      "          9       0.62      0.53      0.57       199\n",
      "         10       0.60      0.72      0.65       455\n",
      "\n",
      "avg / total       0.65      0.69      0.67      1940\n",
      "\n",
      "Probability:  0.4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.66      0.68       161\n",
      "          1       0.53      0.29      0.38        55\n",
      "          2       0.00      0.00      0.00         1\n",
      "          3       0.73      0.70      0.71       240\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.75      0.87      0.81       566\n",
      "          7       0.65      0.43      0.52        75\n",
      "          8       0.49      0.51      0.50       170\n",
      "          9       0.62      0.53      0.57       199\n",
      "         10       0.60      0.71      0.65       455\n",
      "\n",
      "avg / total       0.66      0.69      0.67      1940\n",
      "\n",
      "Probability:  0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.65      0.68       161\n",
      "          1       0.53      0.29      0.38        55\n",
      "          2       0.00      0.00      0.00         1\n",
      "          3       0.73      0.68      0.71       240\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.76      0.87      0.81       566\n",
      "          7       0.65      0.41      0.50        75\n",
      "          8       0.49      0.51      0.50       170\n",
      "          9       0.62      0.52      0.57       199\n",
      "         10       0.61      0.71      0.65       455\n",
      "\n",
      "avg / total       0.66      0.68      0.66      1940\n",
      "\n",
      "Probability:  0.6000000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.64      0.68       161\n",
      "          1       0.55      0.29      0.38        55\n",
      "          2       0.00      0.00      0.00         1\n",
      "          3       0.74      0.68      0.70       240\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.76      0.86      0.81       566\n",
      "          7       0.69      0.41      0.52        75\n",
      "          8       0.49      0.49      0.49       170\n",
      "          9       0.62      0.52      0.57       199\n",
      "         10       0.61      0.69      0.65       455\n",
      "\n",
      "avg / total       0.67      0.67      0.66      1940\n",
      "\n",
      "Probability:  0.7000000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.64      0.68       161\n",
      "          1       0.58      0.27      0.37        55\n",
      "          2       0.00      0.00      0.00         1\n",
      "          3       0.74      0.67      0.70       240\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.77      0.86      0.81       566\n",
      "          7       0.70      0.41      0.52        75\n",
      "          8       0.50      0.49      0.50       170\n",
      "          9       0.63      0.51      0.57       199\n",
      "         10       0.62      0.69      0.65       455\n",
      "\n",
      "avg / total       0.67      0.67      0.66      1940\n",
      "\n",
      "Probability:  0.8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.62      0.67       161\n",
      "          1       0.64      0.25      0.36        55\n",
      "          2       0.00      0.00      0.00         1\n",
      "          3       0.74      0.67      0.70       240\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.78      0.86      0.82       566\n",
      "          7       0.72      0.41      0.53        75\n",
      "          8       0.50      0.47      0.48       170\n",
      "          9       0.63      0.51      0.56       199\n",
      "         10       0.62      0.67      0.65       455\n",
      "\n",
      "avg / total       0.68      0.66      0.66      1940\n",
      "\n",
      "Probability:  0.9\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.61      0.68       161\n",
      "          1       0.62      0.24      0.34        55\n",
      "          2       0.00      0.00      0.00         1\n",
      "          3       0.75      0.66      0.70       240\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.78      0.86      0.82       566\n",
      "          7       0.75      0.40      0.52        75\n",
      "          8       0.52      0.46      0.49       170\n",
      "          9       0.66      0.50      0.57       199\n",
      "         10       0.63      0.65      0.64       455\n",
      "\n",
      "avg / total       0.69      0.65      0.66      1940\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ml_python/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for standard in [x * 0.1 for x in range(1, 10)]:\n",
    "    print(\"Probability: \", standard)\n",
    "    print(classification_report(y_test==1, predict>standard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (other-env)",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
