{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Twitter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from gensim.models import doc2vec\n",
    "\n",
    "pos_tagger = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/x_train.pickle', 'rb') as f:\n",
    "    x_train = pickle.load(f)\n",
    "with open('../input/x_test.pickle', 'rb') as f:\n",
    "    x_test = pickle.load(f)\n",
    "with open('../input/y_train.pickle', 'rb') as f:\n",
    "    y_train = pickle.load(f)\n",
    "with open('../input/y_test.pickle', 'rb') as f:\n",
    "    y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_dr = \"../input/stopword.txt\"\n",
    "f = open(stop_dr, 'r')\n",
    "stopword_korean = set([value.strip() for value in f.readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    return ['/'.join(t) for t in pos_tagger.pos(doc, norm=True, stem=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train  = [[i.split(\"/\")[0] for i in tokenize(j) if i.split(\"/\")[1] in ['Noun','Verb','Adjective'] and i.split(\"/\")[0] not in stopword_korean ]for j in x_train ]\n",
    "#x_train = [','.join(i) for i in x_train]\n",
    "\n",
    "x_test  = [[i.split(\"/\")[0] for i in tokenize(j) if i.split(\"/\")[1] in ['Noun','Verb','Adjective'] and i.split(\"/\")[0] not in stopword_korean ]for j in x_test ]\n",
    "#x_test = [','.join(i) for i in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs = [(token, np.where(label==1.0)[0][0]) for token, label in zip(x_train,y_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')\n",
    "tagged_train_docs = [TaggedDocument(d, [c]) for d, c in train_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vectorizer = doc2vec.Doc2Vec(vector_size=300, alpha=0.025, min_alpha=0.025, seed=1234)\n",
    "doc_vectorizer.build_vocab(tagged_train_docs)\n",
    "\n",
    "for epoch in range(10):\n",
    "    doc_vectorizer.train(tagged_train_docs,total_examples=doc_vectorizer.corpus_count,epochs=doc_vectorizer.epochs)\n",
    "    doc_vectorizer.alpha -= 0.002 \n",
    "    doc_vectorizer.min_alpha = doc_vectorizer.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vector = [doc_vectorizer.infer_vector(i) for i in x_train]\n",
    "test_vector = [doc_vectorizer.infer_vector(i) for i in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability:  0.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.38      0.63      0.47       161\n",
      "          1       0.21      0.36      0.27        55\n",
      "          2       0.00      0.00      0.00         1\n",
      "          3       0.27      0.82      0.41       240\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.33      1.00      0.50         1\n",
      "          6       0.43      0.92      0.59       566\n",
      "          7       0.44      0.05      0.10        75\n",
      "          8       0.17      0.59      0.27       170\n",
      "          9       0.34      0.37      0.35       199\n",
      "         10       0.34      0.98      0.51       455\n",
      "\n",
      "avg / total       0.34      0.76      0.45      1940\n",
      "\n",
      "Probability:  0.2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.50      0.52       161\n",
      "          1       0.26      0.15      0.19        55\n",
      "          2       0.00      0.00      0.00         1\n",
      "          3       0.39      0.62      0.48       240\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.51      0.78      0.62       566\n",
      "          7       1.00      0.03      0.05        75\n",
      "          8       0.24      0.36      0.29       170\n",
      "          9       0.50      0.19      0.28       199\n",
      "         10       0.37      0.94      0.54       455\n",
      "\n",
      "avg / total       0.45      0.62      0.47      1940\n",
      "\n",
      "Probability:  0.30000000000000004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.43      0.52       161\n",
      "          1       0.29      0.09      0.14        55\n",
      "          2       0.00      0.00      0.00         1\n",
      "          3       0.46      0.48      0.47       240\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.59      0.61      0.60       566\n",
      "          7       1.00      0.01      0.03        75\n",
      "          8       0.27      0.20      0.23       170\n",
      "          9       0.44      0.08      0.14       199\n",
      "         10       0.41      0.88      0.56       455\n",
      "\n",
      "avg / total       0.50      0.51      0.45      1940\n",
      "\n",
      "Probability:  0.4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.35      0.47       161\n",
      "          1       0.38      0.05      0.10        55\n",
      "          2       0.00      0.00      0.00         1\n",
      "          3       0.57      0.39      0.46       240\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.66      0.49      0.56       566\n",
      "          7       0.00      0.00      0.00        75\n",
      "          8       0.31      0.12      0.18       170\n",
      "          9       0.37      0.04      0.06       199\n",
      "         10       0.44      0.75      0.55       455\n",
      "\n",
      "avg / total       0.50      0.41      0.41      1940\n",
      "\n",
      "Probability:  0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.29      0.42       161\n",
      "          1       0.43      0.05      0.10        55\n",
      "          2       0.00      0.00      0.00         1\n",
      "          3       0.63      0.34      0.44       240\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.71      0.36      0.48       566\n",
      "          7       0.00      0.00      0.00        75\n",
      "          8       0.33      0.09      0.14       170\n",
      "          9       0.60      0.02      0.03       199\n",
      "         10       0.45      0.57      0.51       455\n",
      "\n",
      "avg / total       0.56      0.32      0.37      1940\n",
      "\n",
      "Probability:  0.6000000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.24      0.37       161\n",
      "          1       0.40      0.04      0.07        55\n",
      "          2       0.00      0.00      0.00         1\n",
      "          3       0.62      0.25      0.36       240\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.74      0.25      0.37       566\n",
      "          7       0.00      0.00      0.00        75\n",
      "          8       0.42      0.08      0.13       170\n",
      "          9       0.50      0.01      0.01       199\n",
      "         10       0.46      0.37      0.41       455\n",
      "\n",
      "avg / total       0.57      0.22      0.29      1940\n",
      "\n",
      "Probability:  0.7000000000000001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.19      0.32       161\n",
      "          1       0.50      0.04      0.07        55\n",
      "          2       0.00      0.00      0.00         1\n",
      "          3       0.73      0.19      0.30       240\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.77      0.16      0.27       566\n",
      "          7       0.00      0.00      0.00        75\n",
      "          8       0.50      0.05      0.09       170\n",
      "          9       0.00      0.00      0.00       199\n",
      "         10       0.43      0.22      0.30       455\n",
      "\n",
      "avg / total       0.55      0.14      0.22      1940\n",
      "\n",
      "Probability:  0.8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.13      0.23       161\n",
      "          1       1.00      0.02      0.04        55\n",
      "          2       0.00      0.00      0.00         1\n",
      "          3       0.77      0.12      0.22       240\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.73      0.07      0.13       566\n",
      "          7       0.00      0.00      0.00        75\n",
      "          8       0.25      0.01      0.02       170\n",
      "          9       0.00      0.00      0.00       199\n",
      "         10       0.38      0.09      0.15       455\n",
      "\n",
      "avg / total       0.53      0.07      0.12      1940\n",
      "\n",
      "Probability:  0.9\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.09      0.17       161\n",
      "          1       1.00      0.02      0.04        55\n",
      "          2       0.00      0.00      0.00         1\n",
      "          3       0.74      0.07      0.13       240\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.81      0.03      0.06       566\n",
      "          7       0.00      0.00      0.00        75\n",
      "          8       0.00      0.00      0.00       170\n",
      "          9       0.00      0.00      0.00       199\n",
      "         10       0.46      0.04      0.07       455\n",
      "\n",
      "avg / total       0.55      0.03      0.06      1940\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ml_python/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "svm = OneVsRestClassifier(SGDClassifier(loss=\"log\", penalty=\"l2\", random_state=40,max_iter=10), n_jobs=-1).fit(train_vector, y_train)\n",
    "predict = svm.predict_proba(test_vector)\n",
    "for standard in [x * 0.1 for x in range(1, 10)]:\n",
    "    print(\"Probability: \", standard)\n",
    "    print(classification_report(y_test==1, predict>standard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (other-env)",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
