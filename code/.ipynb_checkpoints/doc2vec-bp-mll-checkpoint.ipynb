{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Twitter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from gensim.models import doc2vec\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from bp_mll_keras import bp_mll_loss\n",
    "\n",
    "pos_tagger = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../input/x_train.pickle', 'rb') as f:\n",
    "    x_train = pickle.load(f)\n",
    "with open('../input/x_test.pickle', 'rb') as f:\n",
    "    x_test = pickle.load(f)\n",
    "with open('../input/y_train.pickle', 'rb') as f:\n",
    "    y_train = pickle.load(f)\n",
    "with open('../input/y_test.pickle', 'rb') as f:\n",
    "    y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_dr = \"../input/stopword.txt\"\n",
    "f = open(stop_dr, 'r')\n",
    "stopword_korean = set([value.strip() for value in f.readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    return ['/'.join(t) for t in pos_tagger.pos(doc, norm=True, stem=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train  = [[i.split(\"/\")[0] for i in tokenize(j) if i.split(\"/\")[1] in ['Noun','Verb','Adjective'] and i.split(\"/\")[0] not in stopword_korean ]for j in x_train ]\n",
    "#x_train = [','.join(i) for i in x_train]\n",
    "\n",
    "x_test  = [[i.split(\"/\")[0] for i in tokenize(j) if i.split(\"/\")[1] in ['Noun','Verb','Adjective'] and i.split(\"/\")[0] not in stopword_korean ]for j in x_test ]\n",
    "#x_test = [','.join(i) for i in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_docs = [(token, np.where(label==1.0)[0][0]) for token, label in zip(x_train,y_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')\n",
    "tagged_train_docs = [TaggedDocument(d, [c]) for d, c in train_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_vectorizer = doc2vec.Doc2Vec(vector_size=300, alpha=0.025, min_alpha=0.025, seed=1234)\n",
    "doc_vectorizer.build_vocab(tagged_train_docs)\n",
    "\n",
    "for epoch in range(10):\n",
    "    doc_vectorizer.train(tagged_train_docs,total_examples=doc_vectorizer.corpus_count,epochs=doc_vectorizer.epochs)\n",
    "    doc_vectorizer.alpha -= 0.002 \n",
    "    doc_vectorizer.min_alpha = doc_vectorizer.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_vector = np.array([doc_vectorizer.infer_vector(i) for i in x_train])\n",
    "test_vector = np.array([doc_vectorizer.infer_vector(i) for i in x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1343 samples, validate on 150 samples\n",
      "Epoch 1/100\n",
      "1343/1343 [==============================] - 1s 422us/step - loss: 25.1648 - acc: 0.3328 - val_loss: 21.3870 - val_acc: 0.3400\n",
      "Epoch 2/100\n",
      "1343/1343 [==============================] - 0s 233us/step - loss: 22.2388 - acc: 0.3366 - val_loss: 20.2276 - val_acc: 0.3267\n",
      "Epoch 3/100\n",
      "1343/1343 [==============================] - 0s 235us/step - loss: 21.2161 - acc: 0.3500 - val_loss: 19.7054 - val_acc: 0.3333\n",
      "Epoch 4/100\n",
      "1343/1343 [==============================] - 0s 235us/step - loss: 20.7002 - acc: 0.3492 - val_loss: 19.3839 - val_acc: 0.3333\n",
      "Epoch 5/100\n",
      "1343/1343 [==============================] - 0s 235us/step - loss: 20.2891 - acc: 0.3380 - val_loss: 19.1241 - val_acc: 0.3667\n",
      "Epoch 6/100\n",
      "1343/1343 [==============================] - 0s 236us/step - loss: 20.2311 - acc: 0.3470 - val_loss: 18.8556 - val_acc: 0.3667\n",
      "Epoch 7/100\n",
      "1343/1343 [==============================] - 0s 229us/step - loss: 20.1344 - acc: 0.3596 - val_loss: 19.0873 - val_acc: 0.3933\n",
      "Epoch 8/100\n",
      "1343/1343 [==============================] - 0s 231us/step - loss: 19.9395 - acc: 0.3701 - val_loss: 18.9598 - val_acc: 0.4067\n",
      "Epoch 9/100\n",
      "1343/1343 [==============================] - 0s 223us/step - loss: 19.9301 - acc: 0.3797 - val_loss: 18.8845 - val_acc: 0.3867\n",
      "Epoch 10/100\n",
      "1343/1343 [==============================] - 0s 231us/step - loss: 19.8208 - acc: 0.3924 - val_loss: 18.9193 - val_acc: 0.4067\n",
      "Epoch 11/100\n",
      "1343/1343 [==============================] - 0s 230us/step - loss: 19.6869 - acc: 0.3961 - val_loss: 18.8680 - val_acc: 0.4200\n",
      "Epoch 12/100\n",
      "1343/1343 [==============================] - 0s 227us/step - loss: 19.5782 - acc: 0.4214 - val_loss: 18.8440 - val_acc: 0.4333\n",
      "Epoch 13/100\n",
      "1343/1343 [==============================] - 0s 231us/step - loss: 19.5294 - acc: 0.4088 - val_loss: 18.7799 - val_acc: 0.4667\n",
      "Epoch 14/100\n",
      "1343/1343 [==============================] - 0s 232us/step - loss: 19.3149 - acc: 0.4684 - val_loss: 18.3772 - val_acc: 0.5467\n",
      "Epoch 15/100\n",
      "1343/1343 [==============================] - 0s 231us/step - loss: 19.0105 - acc: 0.5034 - val_loss: 18.1382 - val_acc: 0.5200\n",
      "Epoch 16/100\n",
      "1343/1343 [==============================] - 0s 226us/step - loss: 18.9681 - acc: 0.5063 - val_loss: 18.3183 - val_acc: 0.5333\n",
      "Epoch 17/100\n",
      "1343/1343 [==============================] - 0s 229us/step - loss: 18.8251 - acc: 0.5048 - val_loss: 18.1454 - val_acc: 0.5800\n",
      "Epoch 18/100\n",
      "1343/1343 [==============================] - 0s 234us/step - loss: 18.7229 - acc: 0.5316 - val_loss: 18.0895 - val_acc: 0.5800\n",
      "Epoch 19/100\n",
      "1343/1343 [==============================] - 0s 234us/step - loss: 18.4730 - acc: 0.5279 - val_loss: 17.8040 - val_acc: 0.5333\n",
      "Epoch 20/100\n",
      "1343/1343 [==============================] - 0s 234us/step - loss: 18.5134 - acc: 0.5391 - val_loss: 18.0094 - val_acc: 0.5600\n",
      "Epoch 21/100\n",
      "1343/1343 [==============================] - 0s 229us/step - loss: 18.3812 - acc: 0.5316 - val_loss: 17.9715 - val_acc: 0.5667\n",
      "Epoch 22/100\n",
      "1343/1343 [==============================] - 0s 229us/step - loss: 18.3063 - acc: 0.5383 - val_loss: 18.1728 - val_acc: 0.5467\n",
      "Epoch 23/100\n",
      "1343/1343 [==============================] - 0s 227us/step - loss: 18.3845 - acc: 0.5525 - val_loss: 18.1328 - val_acc: 0.5400\n",
      "Epoch 24/100\n",
      "1343/1343 [==============================] - 0s 232us/step - loss: 18.3212 - acc: 0.5599 - val_loss: 17.9195 - val_acc: 0.5800\n",
      "Epoch 25/100\n",
      "1343/1343 [==============================] - 0s 229us/step - loss: 18.0240 - acc: 0.5629 - val_loss: 17.9443 - val_acc: 0.5733\n",
      "Epoch 26/100\n",
      "1343/1343 [==============================] - 0s 234us/step - loss: 17.9772 - acc: 0.5570 - val_loss: 18.0664 - val_acc: 0.5800\n",
      "Epoch 27/100\n",
      "1343/1343 [==============================] - 0s 230us/step - loss: 17.9503 - acc: 0.5592 - val_loss: 17.8779 - val_acc: 0.5600\n",
      "Epoch 28/100\n",
      "1343/1343 [==============================] - 0s 230us/step - loss: 17.8146 - acc: 0.5681 - val_loss: 17.9666 - val_acc: 0.5733\n",
      "Epoch 29/100\n",
      "1343/1343 [==============================] - 0s 229us/step - loss: 17.8500 - acc: 0.5659 - val_loss: 17.9854 - val_acc: 0.5733\n",
      "Epoch 30/100\n",
      "1343/1343 [==============================] - 0s 230us/step - loss: 17.7440 - acc: 0.5666 - val_loss: 17.9033 - val_acc: 0.5667\n",
      "Epoch 31/100\n",
      "1343/1343 [==============================] - 0s 231us/step - loss: 17.5813 - acc: 0.5771 - val_loss: 18.0457 - val_acc: 0.5667\n",
      "Epoch 32/100\n",
      "1343/1343 [==============================] - 0s 230us/step - loss: 17.5128 - acc: 0.5681 - val_loss: 17.9155 - val_acc: 0.5333\n",
      "Epoch 33/100\n",
      "1343/1343 [==============================] - 0s 231us/step - loss: 17.6934 - acc: 0.5853 - val_loss: 18.0764 - val_acc: 0.5733\n",
      "Epoch 34/100\n",
      "1343/1343 [==============================] - 0s 232us/step - loss: 17.5051 - acc: 0.5726 - val_loss: 17.9522 - val_acc: 0.5333\n",
      "Epoch 35/100\n",
      "1343/1343 [==============================] - 0s 231us/step - loss: 17.4829 - acc: 0.5719 - val_loss: 17.9638 - val_acc: 0.5200\n",
      "Epoch 36/100\n",
      "1343/1343 [==============================] - 0s 234us/step - loss: 17.3017 - acc: 0.5674 - val_loss: 18.0955 - val_acc: 0.5333\n",
      "Epoch 37/100\n",
      "1343/1343 [==============================] - 0s 230us/step - loss: 17.4021 - acc: 0.5711 - val_loss: 18.1729 - val_acc: 0.5200\n",
      "Epoch 38/100\n",
      "1343/1343 [==============================] - 0s 230us/step - loss: 17.2074 - acc: 0.5793 - val_loss: 17.9642 - val_acc: 0.5200\n",
      "Epoch 39/100\n",
      "1343/1343 [==============================] - 0s 233us/step - loss: 17.1452 - acc: 0.5845 - val_loss: 18.1371 - val_acc: 0.5467\n",
      "Epoch 40/100\n",
      "1343/1343 [==============================] - 0s 225us/step - loss: 17.0739 - acc: 0.5786 - val_loss: 18.0676 - val_acc: 0.5200\n",
      "Epoch 41/100\n",
      "1343/1343 [==============================] - 0s 227us/step - loss: 16.9528 - acc: 0.5741 - val_loss: 18.1821 - val_acc: 0.5067\n",
      "Epoch 42/100\n",
      "1343/1343 [==============================] - 0s 228us/step - loss: 17.0069 - acc: 0.5920 - val_loss: 18.0809 - val_acc: 0.5333\n",
      "Epoch 43/100\n",
      "1343/1343 [==============================] - 0s 229us/step - loss: 16.9882 - acc: 0.5808 - val_loss: 17.9191 - val_acc: 0.5333\n",
      "Epoch 44/100\n",
      "1343/1343 [==============================] - 0s 228us/step - loss: 16.8406 - acc: 0.5875 - val_loss: 17.7766 - val_acc: 0.5333\n",
      "Epoch 45/100\n",
      "1343/1343 [==============================] - 0s 228us/step - loss: 16.9553 - acc: 0.5830 - val_loss: 18.1939 - val_acc: 0.5400\n",
      "Epoch 46/100\n",
      "1343/1343 [==============================] - 0s 228us/step - loss: 16.8343 - acc: 0.5786 - val_loss: 17.9456 - val_acc: 0.5200\n",
      "Epoch 47/100\n",
      "1343/1343 [==============================] - 0s 226us/step - loss: 16.7443 - acc: 0.5949 - val_loss: 17.6917 - val_acc: 0.5400\n",
      "Epoch 48/100\n",
      "1343/1343 [==============================] - 0s 227us/step - loss: 16.7436 - acc: 0.5912 - val_loss: 17.8849 - val_acc: 0.5133\n",
      "Epoch 49/100\n",
      "1343/1343 [==============================] - 0s 227us/step - loss: 16.5418 - acc: 0.5882 - val_loss: 17.9293 - val_acc: 0.5267\n",
      "Epoch 50/100\n",
      "1343/1343 [==============================] - 0s 228us/step - loss: 16.6192 - acc: 0.6009 - val_loss: 18.0963 - val_acc: 0.5133\n",
      "Epoch 51/100\n",
      "1343/1343 [==============================] - 0s 225us/step - loss: 16.6334 - acc: 0.5957 - val_loss: 18.0435 - val_acc: 0.5267\n",
      "Epoch 52/100\n",
      "1343/1343 [==============================] - 0s 231us/step - loss: 16.6869 - acc: 0.5867 - val_loss: 18.1841 - val_acc: 0.5067\n",
      "Epoch 53/100\n",
      "1343/1343 [==============================] - 0s 233us/step - loss: 16.3826 - acc: 0.6083 - val_loss: 17.8423 - val_acc: 0.5200\n",
      "Epoch 54/100\n",
      "1343/1343 [==============================] - 0s 228us/step - loss: 16.5112 - acc: 0.6009 - val_loss: 17.9022 - val_acc: 0.5267\n",
      "Epoch 55/100\n",
      "1343/1343 [==============================] - 0s 227us/step - loss: 16.5105 - acc: 0.6091 - val_loss: 18.0760 - val_acc: 0.5333\n",
      "Epoch 56/100\n",
      "1343/1343 [==============================] - 0s 232us/step - loss: 16.3481 - acc: 0.6173 - val_loss: 18.2772 - val_acc: 0.5467\n",
      "Epoch 57/100\n",
      "1343/1343 [==============================] - 0s 230us/step - loss: 16.3988 - acc: 0.6061 - val_loss: 18.4911 - val_acc: 0.5333\n",
      "Epoch 58/100\n",
      "1343/1343 [==============================] - 0s 229us/step - loss: 16.2603 - acc: 0.6054 - val_loss: 18.1703 - val_acc: 0.5133\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1343/1343 [==============================] - 0s 230us/step - loss: 16.2426 - acc: 0.6188 - val_loss: 18.1632 - val_acc: 0.5467\n",
      "Epoch 60/100\n",
      "1343/1343 [==============================] - 0s 228us/step - loss: 16.0867 - acc: 0.6128 - val_loss: 18.6741 - val_acc: 0.5200\n",
      "Epoch 61/100\n",
      "1343/1343 [==============================] - 0s 228us/step - loss: 16.2887 - acc: 0.6173 - val_loss: 18.3485 - val_acc: 0.5333\n",
      "Epoch 62/100\n",
      "1343/1343 [==============================] - 0s 228us/step - loss: 16.0673 - acc: 0.6225 - val_loss: 18.5377 - val_acc: 0.5267\n",
      "Epoch 63/100\n",
      "1343/1343 [==============================] - 0s 230us/step - loss: 16.0795 - acc: 0.6054 - val_loss: 18.3725 - val_acc: 0.5467\n",
      "Epoch 64/100\n",
      "1343/1343 [==============================] - 0s 230us/step - loss: 16.0722 - acc: 0.6270 - val_loss: 18.1876 - val_acc: 0.5200\n",
      "Epoch 65/100\n",
      "1343/1343 [==============================] - 0s 227us/step - loss: 16.0982 - acc: 0.6203 - val_loss: 18.6192 - val_acc: 0.5200\n",
      "Epoch 66/100\n",
      "1343/1343 [==============================] - 0s 229us/step - loss: 16.0336 - acc: 0.6225 - val_loss: 18.3531 - val_acc: 0.5133\n",
      "Epoch 67/100\n",
      "1343/1343 [==============================] - 0s 232us/step - loss: 15.9409 - acc: 0.6292 - val_loss: 18.4347 - val_acc: 0.5267\n",
      "Epoch 68/100\n",
      "1343/1343 [==============================] - 0s 233us/step - loss: 15.9224 - acc: 0.6284 - val_loss: 18.7303 - val_acc: 0.5333\n",
      "Epoch 69/100\n",
      "1343/1343 [==============================] - 0s 229us/step - loss: 15.9851 - acc: 0.6158 - val_loss: 18.6911 - val_acc: 0.5533\n",
      "Epoch 70/100\n",
      "1343/1343 [==============================] - 0s 229us/step - loss: 15.9533 - acc: 0.6277 - val_loss: 18.2162 - val_acc: 0.5600\n",
      "Epoch 71/100\n",
      "1343/1343 [==============================] - 0s 228us/step - loss: 15.8137 - acc: 0.6203 - val_loss: 18.7610 - val_acc: 0.5467\n",
      "Epoch 72/100\n",
      "1343/1343 [==============================] - 0s 228us/step - loss: 15.9011 - acc: 0.6180 - val_loss: 18.4043 - val_acc: 0.5533\n",
      "Epoch 73/100\n",
      "1343/1343 [==============================] - 0s 226us/step - loss: 15.8948 - acc: 0.6158 - val_loss: 18.7029 - val_acc: 0.5533\n",
      "Epoch 74/100\n",
      "1343/1343 [==============================] - 0s 227us/step - loss: 15.8144 - acc: 0.6292 - val_loss: 18.8128 - val_acc: 0.5400\n",
      "Epoch 75/100\n",
      "1343/1343 [==============================] - 0s 228us/step - loss: 15.7503 - acc: 0.6262 - val_loss: 18.4449 - val_acc: 0.5533\n",
      "Epoch 76/100\n",
      "1343/1343 [==============================] - 0s 228us/step - loss: 15.6778 - acc: 0.6381 - val_loss: 18.6136 - val_acc: 0.5400\n",
      "Epoch 77/100\n",
      "1343/1343 [==============================] - 0s 230us/step - loss: 15.7289 - acc: 0.6292 - val_loss: 18.6548 - val_acc: 0.5400\n",
      "Epoch 78/100\n",
      "1343/1343 [==============================] - 0s 231us/step - loss: 15.7074 - acc: 0.6247 - val_loss: 18.3926 - val_acc: 0.5333\n",
      "Epoch 79/100\n",
      "1343/1343 [==============================] - 0s 229us/step - loss: 15.6962 - acc: 0.6426 - val_loss: 18.9232 - val_acc: 0.5467\n",
      "Epoch 80/100\n",
      "1343/1343 [==============================] - 0s 227us/step - loss: 15.6504 - acc: 0.6389 - val_loss: 18.8320 - val_acc: 0.5600\n",
      "Epoch 81/100\n",
      "1343/1343 [==============================] - 0s 230us/step - loss: 15.5520 - acc: 0.6255 - val_loss: 18.7193 - val_acc: 0.5333\n",
      "Epoch 82/100\n",
      "1343/1343 [==============================] - 0s 229us/step - loss: 15.6350 - acc: 0.6284 - val_loss: 18.6938 - val_acc: 0.5533\n",
      "Epoch 83/100\n",
      "1343/1343 [==============================] - 0s 228us/step - loss: 15.5765 - acc: 0.6344 - val_loss: 18.6228 - val_acc: 0.5267\n",
      "Epoch 84/100\n",
      "1343/1343 [==============================] - 0s 232us/step - loss: 15.4746 - acc: 0.6314 - val_loss: 18.5998 - val_acc: 0.5533\n",
      "Epoch 85/100\n",
      "1343/1343 [==============================] - 0s 228us/step - loss: 15.5252 - acc: 0.6322 - val_loss: 18.3353 - val_acc: 0.5467\n",
      "Epoch 86/100\n",
      "1343/1343 [==============================] - 0s 230us/step - loss: 15.4628 - acc: 0.6351 - val_loss: 18.5426 - val_acc: 0.5333\n",
      "Epoch 87/100\n",
      "1343/1343 [==============================] - 0s 230us/step - loss: 15.4207 - acc: 0.6441 - val_loss: 18.8455 - val_acc: 0.5333\n",
      "Epoch 88/100\n",
      "1343/1343 [==============================] - 0s 230us/step - loss: 15.4291 - acc: 0.6456 - val_loss: 18.7511 - val_acc: 0.5533\n",
      "Epoch 89/100\n",
      "1343/1343 [==============================] - 0s 227us/step - loss: 15.5779 - acc: 0.6456 - val_loss: 18.6009 - val_acc: 0.5467\n",
      "Epoch 90/100\n",
      "1343/1343 [==============================] - 0s 229us/step - loss: 15.5337 - acc: 0.6389 - val_loss: 18.6859 - val_acc: 0.5467\n",
      "Epoch 91/100\n",
      "1343/1343 [==============================] - 0s 230us/step - loss: 15.4612 - acc: 0.6538 - val_loss: 18.7226 - val_acc: 0.5533\n",
      "Epoch 92/100\n",
      "1343/1343 [==============================] - 0s 229us/step - loss: 15.3414 - acc: 0.6448 - val_loss: 18.6917 - val_acc: 0.5333\n",
      "Epoch 93/100\n",
      "1343/1343 [==============================] - 0s 228us/step - loss: 15.3657 - acc: 0.6575 - val_loss: 18.7670 - val_acc: 0.5200\n",
      "Epoch 94/100\n",
      "1343/1343 [==============================] - 0s 227us/step - loss: 15.3459 - acc: 0.6552 - val_loss: 19.1323 - val_acc: 0.5267\n",
      "Epoch 95/100\n",
      "1343/1343 [==============================] - 0s 230us/step - loss: 15.4203 - acc: 0.6605 - val_loss: 19.4013 - val_acc: 0.5400\n",
      "Epoch 96/100\n",
      "1343/1343 [==============================] - 0s 227us/step - loss: 15.4721 - acc: 0.6508 - val_loss: 18.5393 - val_acc: 0.5200\n",
      "Epoch 97/100\n",
      "1343/1343 [==============================] - 0s 227us/step - loss: 15.3530 - acc: 0.6664 - val_loss: 18.7212 - val_acc: 0.5600\n",
      "Epoch 98/100\n",
      "1343/1343 [==============================] - 0s 230us/step - loss: 15.3474 - acc: 0.6620 - val_loss: 18.8720 - val_acc: 0.5400\n",
      "Epoch 99/100\n",
      "1343/1343 [==============================] - 0s 228us/step - loss: 15.2136 - acc: 0.6493 - val_loss: 19.0679 - val_acc: 0.5333\n",
      "Epoch 100/100\n",
      "1343/1343 [==============================] - 0s 229us/step - loss: 15.2068 - acc: 0.6560 - val_loss: 19.1367 - val_acc: 0.5200\n"
     ]
    }
   ],
   "source": [
    "n = train_vector.shape[0]\n",
    "dim_no = train_vector.shape[1]\n",
    "class_no = y_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_dim=dim_no, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(class_no, activation='sigmoid', kernel_initializer='glorot_uniform'))\n",
    "model.compile(loss=bp_mll_loss, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_vector, y_train, epochs=100,validation_split=0.1)\n",
    "predict = model.predict(test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for standard in [x * 0.1 for x in range(1, 10)]:\n",
    "    print(\"Probability: \", standard)\n",
    "    print(classification_report(y_test==1, predict>standard))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (other-env)",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
